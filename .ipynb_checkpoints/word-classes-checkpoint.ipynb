{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Google Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Worksheet 'Master' id:0>, <Worksheet 'Bachelor' id:1109562875>]\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "credentials = Credentials.from_service_account_file('./sheet-274815-b5805997d72c.json', scopes=scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "sh = gc.open_by_url('https://docs.google.com/spreadsheets/d/1uUxI7ZwIO25GccHz_k6UNMtfvO6SwTuskNBdptV5vyw/edit?usp=sharing')\n",
    "worksheet_list = sh.worksheets()\n",
    "\n",
    "print(worksheet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Worksheet 'Bachelor' id:1109562875>\n"
     ]
    }
   ],
   "source": [
    "degree = 'Bachelor'\n",
    "sheet = sh.worksheet(degree)\n",
    "print(sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import string\n",
    "import json\n",
    "import glob\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "dictionary = { }\n",
    "\n",
    "rows = sheet.row_count\n",
    "print(rows)\n",
    "\n",
    "for i in range(2, rows):\n",
    "    time.sleep(.5)\n",
    "    row = sheet.row_values(str(i))\n",
    "    try:\n",
    "        author = row[0] + ' ' + row[1]\n",
    "        course = row[2]\n",
    "        thesisTitle = row[3]\n",
    "        text = row[4]\n",
    "\n",
    "        doc = nlp(text)\n",
    "        for sentence in doc.sents:\n",
    "            #print(sentence)\n",
    "            \n",
    "            for token in sentence:\n",
    "                \n",
    "                # it groups entities \n",
    "                for j in token.children:\n",
    "                    if j.dep_ == \"compound\":\n",
    "                        \n",
    "                        if str('PROPN') in dictionary:\n",
    "                            if str(j).lower() + ' ' + str(token).lower() in dictionary['PROPN']:\n",
    "                                dictionary['PROPN'][str(j).lower() + ' ' + str(token).lower()].append( author)\n",
    "                            else:\n",
    "                                dictionary['PROPN'][str(j).lower() + ' ' + str(token).lower()] = [author]                            \n",
    "                        else:\n",
    "                            dictionary['PROPN'] = {str(j).lower() + ' ' + str(token).lower():[author]}\n",
    "\n",
    "\n",
    "                if str(token.pos_) in dictionary:     \n",
    "                    if str(token).lower() in dictionary[token.pos_]:\n",
    "                        dictionary[token.pos_][str(token).lower()].append( author)\n",
    "                    else:\n",
    "                        dictionary[token.pos_][str(token).lower()] = [author]\n",
    "                else:\n",
    "                    dictionary[token.pos_] = {str(token).lower():[author]}\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "output = open(\"./dictionary-\" + degree.lower() + \".json\", 'w')\n",
    "json.dump(dictionary, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['VERB', 'ADP', 'DET', 'NOUN', 'PROPN', 'PUNCT', 'PART', 'PRON', 'CCONJ', 'ADV', 'NUM', 'ADJ'])\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stabiliser acting ac- tendency\n",
      "tendency acting close panels\n",
      "terials depending climatic terials\n",
      "panels acting insu- [the, waste, ma-, terials]\n",
      "terials warp uptight [the, waste, ma-, terials]\n",
      "tendency used empower- stabiliser\n",
      "panels depending anonymous stabiliser\n",
      "[the, waste, ma-, terials] resulting pointless tendency\n",
      "[the, waste, ma-, terials] resulting ness stabiliser\n",
      "terials depending juristic terials\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range (0, 10):\n",
    "    noun, author= random.choice(list(dictionary['NOUN'].items()))\n",
    "    verb, author = random.choice(list(dictionary['VERB'].items()))\n",
    "    adj, author = random.choice(list(dictionary['ADJ'].items()))\n",
    "    noun1, author = random.choice(list(dictionary['NOUN'].items()))\n",
    "\n",
    "    print(noun , verb , adj , noun1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PROPN': {Kim: ['author 1'], 'Kardashian': ['author 2'], 'Kim': ['author 7'], 'Trump': ['author 8']}, 'VERB': {expands: ['author 3']}, 'ADJ': {live: ['author 4']}, 'NOUN': {technologies: ['author 5']}, 'ADP': {from: ['author 6']}, 'PUNCT': {.: ['author 9']}}\n"
     ]
    }
   ],
   "source": [
    "if token.dep_ == 'nsubj' or token.dep_ == 'PROPN':\n",
    "        children = [child for child in token.subtree]\n",
    "        #print(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[noun] [verb] [adj] [noun]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
